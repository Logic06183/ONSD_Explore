{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "INFO:root:Loading and preprocessing images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-image module not found. Please install it using '!pip install --user scikit-image'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading labels and images...\n",
      "INFO:root:Applying edge detection...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 284\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# Apply edge detection as additional preprocessing\u001b[39;00m\n\u001b[0;32m    283\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying edge detection...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 284\u001b[0m images_edges \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanny\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    285\u001b[0m images_edges \u001b[38;5;241m=\u001b[39m images_edges[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Normalize images\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 284\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# Apply edge detection as additional preprocessing\u001b[39;00m\n\u001b[0;32m    283\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying edge detection...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 284\u001b[0m images_edges \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mfeature\u001b[49m\u001b[38;5;241m.\u001b[39mcanny(img\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images])\n\u001b[0;32m    285\u001b[0m images_edges \u001b[38;5;241m=\u001b[39m images_edges[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Normalize images\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature' is not defined"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install --user tensorflow\n",
    "!pip install --user xgboost\n",
    "!pip install --user opencv-python-headless\n",
    "!pip install --user imgaug\n",
    "!pip install --user scikit-image\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, train_test_split  # Added train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Flatten, Dense, Dropout,\n",
    "    Input, BatchNormalization, Activation, concatenate\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "try:\n",
    "    from skimage import feature\n",
    "except ModuleNotFoundError:\n",
    "    print(\"scikit-image module not found. Please install it using '!pip install --user scikit-image'\")\n",
    "\n",
    "# Rest of your code continues...\n",
    "\n",
    "# Rest of your code continues...\n",
    "\n",
    "\n",
    "# Set logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "IMAGE_DIR = './documents'\n",
    "PREPROCESSED_DIR = './documents/preprocessed_images'\n",
    "EXCEL_FILE = 'Meta_pic_3.xlsx'\n",
    "LEFT, TOP, IMG_WIDTH, IMG_HEIGHT = 232, 60, 495, 475\n",
    "RIGHT, BOTTOM = LEFT + IMG_WIDTH, TOP + IMG_HEIGHT\n",
    "CROP_TOP, CROP_HEIGHT, CROP_LEFT, CROP_WIDTH = 290, 100, 215, 125\n",
    "CROP_BOTTOM, CROP_RIGHT = CROP_TOP + CROP_HEIGHT, CROP_LEFT + CROP_WIDTH\n",
    "MAX_FEATURES, GOOD_MATCH_PERCENT, MAX_DELTA = 500, 0.15, 200\n",
    "MIN_DELTA_X, MAX_DELTA_X = -CROP_LEFT, IMG_WIDTH - CROP_RIGHT\n",
    "MIN_DELTA_Y, MAX_DELTA_Y = -CROP_TOP, IMG_HEIGHT - CROP_BOTTOM\n",
    "NUM_FOLDS = 5  # For K-fold cross-validation\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(PREPROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Configure TensorFlow to avoid OOM errors\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logging.info(\"GPU memory growth set\")\n",
    "    except RuntimeError as e:\n",
    "        logging.warning(e)\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images(image_dir):\n",
    "    image_files = [file for file in os.listdir(image_dir) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    images = []\n",
    "    for file in image_files:\n",
    "        img_path = os.path.join(image_dir, file)\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img_cropped = img.crop((LEFT, TOP, RIGHT, BOTTOM))\n",
    "        images.append((file, np.array(img_cropped)))\n",
    "    return images\n",
    "\n",
    "# Function for image alignment using ORB\n",
    "def align_images(reference_image, images):\n",
    "    aligned_images = []\n",
    "    offsets = []\n",
    "    orb = cv2.ORB_create(MAX_FEATURES)\n",
    "    ref_kp, ref_des = orb.detectAndCompute(reference_image, None)\n",
    "    for filename, img in images:\n",
    "        try:\n",
    "            kp, des = orb.detectAndCompute(img, None)\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            matches = bf.match(ref_des, des)\n",
    "            matches = sorted(matches, key=lambda x: x.distance)\n",
    "            matches = matches[:int(len(matches) * GOOD_MATCH_PERCENT)]\n",
    "            points1 = np.float32([ref_kp[m.queryIdx].pt for m in matches])\n",
    "            points2 = np.float32([kp[m.trainIdx].pt for m in matches])\n",
    "            deltas = points2 - points1\n",
    "            # Filter deltas\n",
    "            deltas = deltas[(deltas[:, 0] > MIN_DELTA_X) & (deltas[:, 0] < MAX_DELTA_X) &\n",
    "                            (deltas[:, 1] > MIN_DELTA_Y) & (deltas[:, 1] < MAX_DELTA_Y)]\n",
    "            if len(deltas) == 0:\n",
    "                offset = (0, 0)\n",
    "            else:\n",
    "                # Clustering to find the most consistent offset\n",
    "                clustering = DBSCAN(eps=10, min_samples=5).fit(deltas)\n",
    "                labels, counts = np.unique(clustering.labels_, return_counts=True)\n",
    "                if len(labels) > 1:\n",
    "                    max_label = labels[np.argmax(counts[labels != -1])]\n",
    "                    offset = deltas[clustering.labels_ == max_label].mean(axis=0)\n",
    "                else:\n",
    "                    offset = deltas.mean(axis=0)\n",
    "            offsets.append(offset)\n",
    "            aligned_images.append((filename, img))\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Alignment failed for {filename}: {e}\")\n",
    "            offsets.append((0, 0))\n",
    "            aligned_images.append((filename, img))\n",
    "    return aligned_images, offsets\n",
    "\n",
    "# Function to preprocess images (cropping and saving)\n",
    "def preprocess_and_save_images(images, offsets, preprocessed_dir):\n",
    "    os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "    for (filename, img), offset in zip(images, offsets):\n",
    "        offset_left, offset_top = offset\n",
    "        cropped_top = int(CROP_TOP + offset_top)\n",
    "        cropped_bottom = int(CROP_BOTTOM + offset_top)\n",
    "        cropped_left = int(CROP_LEFT + offset_left)\n",
    "        cropped_right = int(CROP_RIGHT + offset_left)\n",
    "        # Ensure the cropping is within image bounds\n",
    "        if (0 <= cropped_top < cropped_bottom <= img.shape[0]) and \\\n",
    "           (0 <= cropped_left < cropped_right <= img.shape[1]):\n",
    "            cropped_img = img[cropped_top:cropped_bottom, cropped_left:cropped_right]\n",
    "            preprocessed_path = os.path.join(preprocessed_dir, filename)\n",
    "            Image.fromarray(cropped_img).save(preprocessed_path)\n",
    "        else:\n",
    "            logging.warning(f\"Cropping out of bounds for {filename}\")\n",
    "\n",
    "# Function to apply image augmentation\n",
    "def augment_images(images, labels):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    for img, label in zip(images, labels):\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "        aug_iter = datagen.flow(img, batch_size=1)\n",
    "        for _ in range(3):  # Generate 3 augmented images per original image\n",
    "            aug_img = next(aug_iter)[0].astype('float32')\n",
    "            augmented_images.append(aug_img)\n",
    "            augmented_labels.append(label)\n",
    "    return np.array(augmented_images), np.array(augmented_labels)\n",
    "\n",
    "# Function to load labels and match with images\n",
    "def load_labels_and_images(excel_file, preprocessed_dir):\n",
    "    df = pd.read_excel(excel_file)\n",
    "    df['filename'] = df['record_id'].astype(str) + '_image_data_' + df['redcap_repeat_instance'].astype(str) + '_raw_image.jpg'\n",
    "    df['onsd'] = df['onsd'].astype(str).str.replace(',', '.').astype(float)\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = os.path.join(preprocessed_dir, row['filename'])\n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path).resize((128, 128))\n",
    "            images.append(np.array(img))\n",
    "            labels.append(row['onsd'])\n",
    "        else:\n",
    "            logging.warning(f\"Preprocessed image not found: {row['filename']}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to build UNet model\n",
    "def build_unet_model(input_shape=(128, 128, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # Encoder\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Decoder\n",
    "    u3 = tf.keras.layers.UpSampling2D((2, 2))(c2)\n",
    "    u3 = concatenate([u3, c1])\n",
    "    c3 = Conv2D(16, (3, 3), activation='relu', padding='same')(u3)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Conv2D(16, (3, 3), activation='relu', padding='same')(c3)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='linear')(c3)\n",
    "    outputs = Flatten()(outputs)\n",
    "    outputs = Dense(1)(outputs)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Function to perform K-fold cross-validation\n",
    "def cross_validate_model(model_fn, X, y, n_splits=NUM_FOLDS, epochs=25, batch_size=32):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "    all_scores = []\n",
    "    for train_index, val_index in kfold.split(X, y):\n",
    "        logging.info(f'Training fold {fold_no}')\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        model = model_fn()\n",
    "        model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "        # Early stopping and model checkpoint\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=5, restore_best_weights=True),\n",
    "            ModelCheckpoint(f'model_fold_{fold_no}.h5', save_best_only=True)\n",
    "        ]\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                  validation_data=(X_val, y_val), callbacks=callbacks, verbose=0)\n",
    "        scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "        logging.info(f'Fold {fold_no} MAE: {scores[1]}')\n",
    "        all_scores.append(scores[1])\n",
    "        fold_no += 1\n",
    "    avg_score = np.mean(all_scores)\n",
    "    logging.info(f'Average MAE over {n_splits} folds: {avg_score}')\n",
    "    return avg_score\n",
    "\n",
    "# Function to build and train ensemble models\n",
    "def train_ensemble_models(X_train_flat, y_train):\n",
    "    estimators = [\n",
    "        ('rf', RandomForestRegressor(random_state=42)),\n",
    "        ('xgb', XGBRegressor(random_state=42))\n",
    "    ]\n",
    "    # Stacking Regressor\n",
    "    stack_model = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LinearRegression(),\n",
    "        cv=NUM_FOLDS,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    stack_model.fit(X_train_flat, y_train)\n",
    "    return stack_model\n",
    "\n",
    "# Function to perform hyperparameter tuning\n",
    "def tune_hyperparameters(X_train_flat, y_train):\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'subsample': [0.8, 1],\n",
    "    }\n",
    "    xgb = XGBRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(xgb, param_grid, scoring='neg_mean_absolute_error', cv=NUM_FOLDS, n_jobs=-1)\n",
    "    grid_search.fit(X_train_flat, y_train)\n",
    "    logging.info(f'Best parameters found: {grid_search.best_params_}')\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Main execution flow\n",
    "if __name__ == '__main__':\n",
    "    # Load and preprocess images\n",
    "    logging.info(\"Loading and preprocessing images...\")\n",
    "    raw_images = load_and_preprocess_images(IMAGE_DIR)\n",
    "    reference_image = raw_images[0][1]\n",
    "    aligned_images, offsets = align_images(reference_image, raw_images)\n",
    "    preprocess_and_save_images(aligned_images, offsets, PREPROCESSED_DIR)\n",
    "\n",
    "    # Load labels and images\n",
    "    logging.info(\"Loading labels and images...\")\n",
    "    images, labels = load_labels_and_images(EXCEL_FILE, PREPROCESSED_DIR)\n",
    "\n",
    "    # Apply edge detection as additional preprocessing\n",
    "    logging.info(\"Applying edge detection...\")\n",
    "    images_edges = np.array([feature.canny(img.astype('float32') / 255.0) for img in images])\n",
    "    images_edges = images_edges[..., np.newaxis]\n",
    "\n",
    "    # Normalize images\n",
    "    images = images.astype('float32') / 255.0\n",
    "    images = images[..., np.newaxis]\n",
    "\n",
    "    # Augment images\n",
    "    logging.info(\"Augmenting images...\")\n",
    "    images_augmented, labels_augmented = augment_images(images, labels)\n",
    "    images_combined = np.vstack((images, images_augmented))\n",
    "    labels_combined = np.hstack((labels, labels_augmented))\n",
    "\n",
    "    # Split data\n",
    "    logging.info(\"Splitting data...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images_combined, labels_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build and cross-validate UNet model\n",
    "    logging.info(\"Building and cross-validating UNet model...\")\n",
    "    unet_mae = cross_validate_model(build_unet_model, X_train, y_train)\n",
    "\n",
    "    # Prepare data for traditional ML models\n",
    "    logging.info(\"Preparing data for traditional ML models...\")\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    logging.info(\"Hyperparameter tuning for XGBoost...\")\n",
    "    xgb_best = tune_hyperparameters(X_train_flat, y_train)\n",
    "\n",
    "    # Train ensemble model\n",
    "    logging.info(\"Training ensemble model...\")\n",
    "    stack_model = train_ensemble_models(X_train_flat, y_train)\n",
    "\n",
    "    # Evaluate models\n",
    "    logging.info(\"Evaluating models...\")\n",
    "    # UNet evaluation\n",
    "    unet_model = build_unet_model()\n",
    "    unet_model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "    unet_model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
    "    unet_predictions = unet_model.predict(X_test).flatten()\n",
    "    unet_mae = mean_absolute_error(y_test, unet_predictions)\n",
    "    unet_rmse = np.sqrt(mean_squared_error(y_test, unet_predictions))\n",
    "\n",
    "    # XGBoost evaluation\n",
    "    xgb_predictions = xgb_best.predict(X_test_flat)\n",
    "    xgb_mae = mean_absolute_error(y_test, xgb_predictions)\n",
    "    xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n",
    "\n",
    "    # Ensemble evaluation\n",
    "    stack_predictions = stack_model.predict(X_test_flat)\n",
    "    stack_mae = mean_absolute_error(y_test, stack_predictions)\n",
    "    stack_rmse = np.sqrt(mean_squared_error(y_test, stack_predictions))\n",
    "\n",
    "    # Compile results\n",
    "    logging.info(\"Compiling results...\")\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Model': ['UNet', 'XGBoost (Tuned)', 'Ensemble (Stacked)'],\n",
    "        'MAE': [unet_mae, xgb_mae, stack_mae],\n",
    "        'RMSE': [unet_rmse, xgb_rmse, stack_rmse]\n",
    "    })\n",
    "\n",
    "    # Print comparison results\n",
    "    print(comparison_df)\n",
    "\n",
    "    # Save comparison results\n",
    "    comparison_df.to_csv('optimized_model_comparison.csv', index=False)\n",
    "\n",
    "    # Plot MAE comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(comparison_df['Model'], comparison_df['MAE'], color='skyblue')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Mean Absolute Error (MAE)')\n",
    "    plt.title('Model Comparison - MAE')\n",
    "    plt.savefig('optimized_model_mae_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Bland-Altman Plot for UNet\n",
    "    def bland_altman_plot(actual, predicted, model_name):\n",
    "        difference = actual - predicted\n",
    "        avg = (actual + predicted) / 2\n",
    "        mean_diff = np.mean(difference)\n",
    "        std_diff = np.std(difference)\n",
    "        upper_limit = mean_diff + 1.96 * std_diff\n",
    "        lower_limit = mean_diff - 1.96 * std_diff\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(avg, difference, alpha=0.5)\n",
    "        plt.axhline(mean_diff, color='red', linestyle='--', label='Mean Difference')\n",
    "        plt.axhline(upper_limit, color='gray', linestyle='--', label='Upper Limit')\n",
    "        plt.axhline(lower_limit, color='gray', linestyle='--', label='Lower Limit')\n",
    "        plt.xlabel('Average of Actual and Predicted')\n",
    "        plt.ylabel('Difference between Actual and Predicted')\n",
    "        plt.title(f'Bland-Altman Plot - {model_name}')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'bland_altman_{model_name.lower().replace(\" \", \"_\")}.png')\n",
    "        plt.show()\n",
    "\n",
    "    bland_altman_plot(y_test, unet_predictions, 'UNet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
